---
layout: default
active_page: research
---

<!doctype html>
<html>
  <body>
    <h1>Papers</h1>

    <h4> A Passively Bendable, Compliant Tactile Palm with RObotic Modular Endoskeleton Optical (ROMEO) Fingers</h4>
    <p>
        <strong>Sandra Q. Liu</strong>
        and Edward H. Adelson <br>
        IEEE International Conference on Robotics and Automation (ICRA) 2024 <br>
        Also presented at an <a href="https://sites.google.com/view/ws-icra-24-bias/", 
        style="color:black; text-decoration:underline;">ICRA 2024 Workshop on End-Effectors</a><br>
        <a href="https://news.mit.edu/2024/robotic-palm-mimics-human-touch-0520" style="color:rgb(75, 75, 75); text-decoration: underline"><strong>News</strong></a>
        <a href="https://www.youtube.com/watch?v=RKfIFiewqsg" style="color:rgb(75, 75, 75); margin-left:25px; text-decoration: underline"><strong>Video</strong></a>
        <a href="https://arxiv.org/abs/2404.08227" style="color:rgb(75, 75, 75); margin-left:25px; text-decoration: underline"><strong>Arxiv</strong></a>
    </p>
    <p>
        <img src="images/GelPalm.png" alt="gelpalm" width="500"/>
    </p>
    <p>
        The development of a novel compliant high-resolution tactile "GelPalm" with
        modular tactile fingers, allowing the hand to grab various objects
        and see the contact surfaces. Also includes the design of a Flexible
        lighting system for the GelSight-inspired sensors, with the idea that they
        can easily be integrated into other soft robotic systems.
    </p>

    <h4> Scalable Simulation-Guided Compliant Tactile Finger Design </h4>
    <p>
        Yuxiang Ma*, Arpit Agarwal*, 
        <strong>Sandra Q. Liu*</strong>,
        and Edward H. Adelson <br>
        IEEE International Conference on Soft Robotics (RoboSoft) 2024 <br>
        <a href="https://www.youtube.com/watch?v=CnTUTA5cfMw" style="color:rgb(75, 75, 75); text-decoration: underline;"><strong>Video</strong></a>
        <a href="https://arxiv.org/abs/2403.04638" style="color:rgb(75, 75, 75); margin-left:25px; text-decoration: underline"><strong>Arxiv</strong></a>
    </p>
    <p>
        <img src="images/robosoft2024finraysim.jpg" alt="robosoft2024finraysim" width="500"/>
    </p>
    <p>
        A framework which allows users to rapidly design different compliant high-resolution
        tactile fingers, simulate the tactile images, tweak the designs, and then fabricate
        the fingers.
    </p>

    <h4> Object Recognition and Force Estimation with the GelSight Baby Fin Ray </h4>
    <p>
        <strong>Sandra Q. Liu</strong>,
        Yuxiang Ma,
        and Edward H. Adelson <br>
        Conference on Robot Learning (CoRL) 2023 Workshop on <a href="https://sites.google.com/view/corl-2023-soft-robots-ws", 
        style="color:black; text-decoration: underline;">Learning for Soft Robots</a><br>
        <a href="https://www.arxiv.org/abs/2509.14510" style="color:rgb(75, 75, 75); text-decoration: underline"><strong>Arxiv</strong></a>
    </p>
    <p>
        <img src="images/nut_classification_neural_network.png" alt="nutclassification" width="500"/>
    </p>
    <p>
        Using the GelSight Baby Fin Ray, which is a compliant finger with GelSight-inspired
        sensors, to classify nut shell textures and determine forces imparted on the finger.
    </p>
    
    <h4>GelSight EndoFlex: A Soft Endoskeleton Hand with Continuous High-Resolution Tactile Sensing</h4>
    <p>
        <strong>Sandra Q. Liu*</strong>,
        Leonardo Zamora Ya&ntilde;ez*, and
        Edward H. Adelson <br>
        IEEE International Conference on Soft Robotics (RoboSoft) 2023 <br>
        <strong>Winner of Best Student Paper Award</strong> <br>
        <a href="https://news.mit.edu/2023/robotic-hand-can-identify-objects-just-one-grasp-0403" style="color:rgb(75, 75, 75); text-decoration: underline"><strong>News</strong></a>
        <a href="https://www.youtube.com/watch?v=H1OYADtgj9k" style="color:rgb(75, 75, 75); margin-left:25px; text-decoration: underline"><strong>Video</strong></a>
        <a href="https://arxiv.org/abs/2303.17935" style="color:rgb(75, 75, 75); margin-left:25px; text-decoration: underline"><strong>Arxiv</strong></a>
        <a href="https://patents.google.com/patent/US20240308067A1/en" style="color:rgb(75, 75, 75); margin-left:25px; text-decoration: underline"><strong>Patent</strong></a>
    </p>
    <p>
        <img src="images/GelSightEndoFlex.png" alt="gelsightendoflex" width="500"/>
    </p>
    <p>
        Designing soft robotic fingers with internal skeleton structures and
        continuous high-resolution tactile sensing along their entire lengths
        and sides. The fingers are then placed into a hand to demonstrate
        that it can identify objects with just one grasp.
    </p>

    <h4>GelSight Baby Fin Ray: A Compact, Compliant, Flexible Finger with High-Resolution Tactile Sensing</h4>
    <p> 
      <strong>Sandra Q. Liu</strong>,
      Yuxiang Ma
      and Edward H. Adelson <br>
      IEEE International Conference on Soft Robotics (RoboSoft) 2023 <br>
      <a href="https://www.youtube.com/watch?v=_oD_QFtYTPM" style="color:rgb(75, 75, 75); text-decoration: underline;"><strong>Video</strong></a>
      <a href="https://arxiv.org/abs/2303.14883" style="color:rgb(75, 75, 75); margin-left:25px; text-decoration: underline"><strong>Arxiv</strong></a>
    </p>
    <p>
      <img src="images/GelSightBabyFinRay.png" alt="gelsightbabyfinray" width="500"/>
    </p>
    <p>
        A miniaturization of the GelSight Fin Ray using a novel synthesized
        fluorescent silicone paint, giving the resulting finger a compact
        and more flexible design. The camera is moved to the base of the finger
        and looks at a compliant mirror surface on the back of the finger. 
    </p>

    <h4>GelSight Fin Ray: Incorporating Tactile Sensing into a Soft Compliant Robotic Gripper</h4>
    <p> 
      <strong>Sandra Q. Liu</strong>
      and Edward H. Adelson <br>
      IEEE International Conference on Soft Robotics (RoboSoft) 2022 <br>
      <a href="https://news.mit.edu/2022/flexible-way-grab-items-feeling-0415" style="color:rgb(75, 75, 75); text-decoration: underline"><strong>News</strong></a>
      <a href="https://www.youtube.com/watch?v=rvezSGdFPx0" style="color:rgb(75, 75, 75); margin-left:25px; text-decoration: underline"><strong>Video</strong></a>
      <a href="https://arxiv.org/abs/2204.07146" style="color:rgb(75, 75, 75); margin-left:25px; text-decoration: underline"><strong>Arxiv</strong></a>
      <a href="https://patents.google.com/patent/US12135254B2/en" style="color:rgb(75, 75, 75); margin-left:25px; text-decoration: underline"><strong>Patent</strong></a>
    </p>
    <p>
      <img src="images/GelSightFinRay.png" alt="gelsightfinray" width="500"/>
    </p>
    <p>
        The first development of a flexible GelSight-inspired sensor, done
        in a Fin Ray finger form factor. Introducing the fluorescent paint
        allows the sensor to only use the blue LED color and still obtain
        the red, green, and blue channels in the tactile images. The resulting
        system is able to 3D reconstruct tactile images and also perform tasks
        such as reorienting and gently placing down a wine glass on the table.
    </p>

    <h4>Exoskeleton-covered soft finger with vision-based proprioception and tactile sensing</h4>
    <p>
      Yu She*, 
      <strong>Sandra Q. Liu*</strong>,
      Peiyu Yu*, and Edward H. Adelson <br>
      *denotes equal contribution <br>
      IEEE International Conference on Robotics and Automation (ICRA) 2020 <br>
      <a href="https://news.mit.edu/2020/giving-soft-robots-senses-0601" style="color:rgb(75, 75, 75); text-decoration: underline"><strong>News</strong></a>
      <a href="https://arxiv.org/abs/1910.01287" style="color:rgb(75, 75, 75); margin-left:25px; text-decoration: underline"><strong>Arxiv</strong></a>
    </p>
    <p>
      <img src="images/GelFlex.png" alt="exoskeletonfinger" width="500"/>
    </p>
    <p>
        Manufacturing a soft finger with an exoskeleton and embedded camera.
        The camera is able to see tactile images, classify box/cylindrical
        objects, and also estimate the finger's shape.
    </p>
    
    <h1>Talks</h1>
    <p>
        <a href="https://www.youtube.com/watch?v=XKLmAha_Buw",
        style="color:black; text-decoration: underline;">MIT Abstracts</a> [October 2024]
    </p>

    <p>
        Bristol Softlab Seminar [September 2024]
    </p>

    <p>
        <a href="https://csci.williams.edu/computer-science-colloquium-sandra-liu-mit/",
        style="color:black; text-decoration: underline;">Williams College Computer Science Colloquium</a> [May 2023]
    </p>

    <p>
        CMU Robotics Institute Seminar [August 2022]
    </p>

    <h1>Theses</h1>

    <h4>
        <a href="https://www.proquest.com/openview/88aaba9e5eb96d75dbff823e7a4035cf/1?pq-origsite=gscholar&cbl=18750&diss=y"
        style="color:black; text-decoration: underline;">Compliant Tactile Robotic Manipulators</a>
    </h4>
    <p>
      PhD Thesis, Massachusetts Institute of Technology, January 2024
    </p>

    <h4>
        <a href="https://dspace.mit.edu/handle/1721.1/127131"
        style="color:black; text-decoration: underline;">Vision-based proprioception of a soft robotic finger with tactile sensing</a>
    </h4>
    <p>
      Master's Thesis, Massachusetts Institute of Technology, June 2020
    </p>

  </body>
</html>